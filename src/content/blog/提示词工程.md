---
author: Kiera
pubDatetime: 2025-03-21
modDatetime: 2025-03-21
title: 提示词工程优化
slug: AI
featured: true
draft: false
tags:
  - 提示词
description: 对prompt（提示词）的调整和优化手段
---

## 基础

### 1. 提示词优化

提示词优化是一种对人工智能模型 prompt（提示词）的调整和优化手段，目的在于提高输出质量，增强相关性，提升用户体验。

优化方法：

- 明确意图
- 细化细节
- 调整结构
- 优化语言
- 示例驱动

### 2. Few-shot 学习

Few-shot 学习指的是模型在只有少量学习样本的情况下仍然能更快速准确地学习并适应新内容或新任务。其目标是让模型能够像人类一样，在数据有限的情况下，快速学习和适应新知识，提高学习效率和灵活性。

### 3. LLM（大语言模型）

Large Language Model（大语言模型）通过在海量的文本数据上进行训练，学会了生成和理解人类语言。它具有强大的语言规模参数以及表达能力，能够处理各种自然语言相关的任务。

### 4. 提示词优化效果评估

评估一个优化后的提示词是否有效，可以从以下几个方面进行：

- 输出准确性
- 输出一致性
- 输出相关性
- 任务完成度
- 用户满意度

### 5. RAG（检索增强生成）

RAG 是一种结合了检索技术和生成式模型的方法，主要用于提高人工智能的准确性和相关性。

工作原理：

1. 问题接收
2. 检索信息文档
3. 生成回答

### 6. 提示词优化的六个策略

- 编写清晰说明
- 提供参考文本
- 将复杂任务拆分为简单的子任务
- 给模型时间思考
- 使用外部工具（external tools）
- 系统地测试更改

### 7. 常用技巧

- 使用清晰、详细、明确的语言描述，避免模糊的词语
- 角色扮演
- 告诉用户角色
- 指定输出格式
- 少样本提示

### 8. Prompt 调优原则

- 简洁：尽量用简短的方式表述问题，避免冗长导致混淆
- 具体：避免模糊抽象的问题
- 详细上下文：提供足够的背景信息以帮助模型理解
- 避免歧义：明确词语或短语的准确含义
- 逻辑清晰：避免逻辑混淆和矛盾

### 9. Prompt 的典型构成

- 角色：给 AI 匹配一个合适的角色
- 指示：对任务进行描述
- 上下文：给出任务相关的背景信息
- 例子：必要时举出例子（one-shot learning, few-shot learning）
- 输入：任务的输入信息
- 输出：输出的格式描述

## 进阶

### 1. 零样本提示

零样本提示是指直接向模型提问，如"中国的首都在哪里"。虽然 LLM 展示了惊人的零样本能力，但在处理复杂任务时仍存在不足。

### 2. 少样本提示

少样本提示是一种通过提供少量示例来引导模型实现更好性能的技术。

### 3. 少样本提示的限制

即使提供了少样本提示，模型也可能无法得到正确的响应，特别是在处理推理类问题时。

### 4. 链式思考（思维链 CoT）

通过中间推理步骤实现复杂的推理能力，可以与少样本提示结合使用，以获得更好的结果。

### 5. 少样本思维链（Few-shot CoT）

### 6. 零样本 CoT 提示

例如："让我们逐步思考"

### 7. 自洽性

自洽性是一种对抗幻觉的手段，类似于做数学题时的多次验算。可以通过以下方式实现：

- 同样的 prompt 多次运行
- 通过投票选出最终结果

### 8. 思维树（Tree-of-Thought, TOT）

基于思维链进行总结，引导 LLM 探索把思维作为中间步骤来解决通用问题。

TOT 通过维护一棵思维树，思维由连贯的语言序列表示，这个序列就是解决问题的中间步骤。

步骤：

1. 在思维链的每一步，采样多个分支
2. 拓扑展开成一个思维树
3. 判断每个分支的任务完成度，以便进行启发式搜索
4. 设计搜索算法
5. 判断叶子结点的任务完成的正确性

### 9. 提示词应用场景

- 生成数据
- 生成代码
- 生成 MySQL 查询语句

### 10. 防止 Prompt 攻击

Prompt 攻击是指攻击者通过精心设计恶意构造的提示词试图误导或操控大模型，使其生成不符合预期、有害或不适当的内容。

工作原理：

- 利用模型对 prompt 的依赖性
- 触发模型的漏洞和盲点
- 绕过安全机制

常见类型：

- 幻觉攻击：使模型生成虚假或误导性信息
- 越狱攻击：绕过模型的伦理和安全限制
- 注入攻击：在提示词中注入恶意内容

防范措施：

- 提示词过滤与审核
- 模型加固与训练
- 用户教育和意识提升
- 安全机制增强

### 11. 如何识别提示词攻击？

- 异常提示词检测：长度分析、结构分析、字符分析
- 输出内容审核：内容过滤、逻辑一致性检查、事实核查
- 上下文分析：对话历史检查、意图识别
- 模型行为分析：生成速度监测、错误率分析
- 对比正常响应：基线对比、多模型验证
- 用户反馈：用户投诉分析、用户交互监测

### 12. 如何处理攻击？

- 应急处理：隔离系统、停止服务、收集证据
- 问题分析：攻击类型判断、漏洞查找、影响评估
- 系统恢复：清理恶意内容、模型重新训练、安全机制恢复
- 预防改进：加强安全防护、对抗训练、用户教育、监控与预警

## RAG 技术详解

### 1. LLM 的缺陷

- 知识不是实时更新的
- LLM 可能不知道私有知识领域
- LLM 可能会生成看似正确但错误的答案

### 2. 使用 RAG 的原因

- 提高准确性
- 减少训练成本
- 适应性强

### 3. RAG 的定义

RAG（检索增强生成）是一种结合了检索技术和生成式模型的方法，主要用于提高人工智能的准确性和相关性。

工作原理：

1. 问题接收
2. 检索信息文档
3. 生成回答
4. 输出回答

关键点：利用外部知识库来增强生成模型的准确性和相关性

适用场景：需要处理和回答大量信息的场景，如智能客服、搜索引擎、问答系统等

### 4. RAG vs Fine-tuning

- RAG：将内部文档进行 embedding，借助检索获得知识范围答案，再结合 prompt 给到 LLM 生成适配答案
- Fine-tuning：用数据集对 LLM 局部参数进行调整，提高 zero-shot 能力

### 5. RAG 工作流程

1. 问题接收
2. 检索信息文档
3. 生成回答
4. 输出回答

![RAG 工作流程](attachment:41b2e593-74cd-4a55-ac08-c0d27b38fd5d:image.png)

### 6. RAG 的搭建流程

#### 索引阶段

1. 搜索和提取各种格式的数据源
2. 转换为统一的纯文本格式
3. 分割成更小的块以适应上下文限制
4. 使用嵌入模型将块编码成向量表示
5. 存储在向量数据库中

#### 检索阶段

1. 将用户查询转换为向量表示
2. 在知识库中查询向量与块向量的相似性得分
3. 选择相似度最高的 Top-k 块

### 7. 向量计算方式

- 欧式距离
- 余弦距离

### 8. 文档处理

- 加载：读取文本
- 分割：有交集但保持原文完整（有冗余信息增大容量，不可避免但也增强了当前的语义环境）

### 9. 向量检索

- 关键字搜索：将相关信息存在 Redis 中
- 语义搜索：关键词 + 词汇之间的语义关系

### 10. 常用向量数据库

- Pinecone
- Milvus
- Chroma
- Faiss

### 11. RAG 的缺陷及应对策略

#### 索引过程缺陷

1. 内容缺失

   - 增加相应知识库
   - 数据清洗与增强
   - 优化 prompt 设计

2. 文档加载问题

   - 优化文档读取器

3. 文档切分问题
   - 固定长度的分块
   - 内容重叠分块
   - 基于结构的分块
   - 基于递归的分块
   - 优化分块大小选择

#### 查询过程缺陷

1. 错过排名靠前的文档

   - 增加召回 top-k 数量
   - 重排

2. 其他问题
   - 提取上下文与文档无关
   - 格式错误（通过 prompt 调优解决）
   - 答案不完整（引导用户精简回答/拆分处理）
   - 未提取到答案
   - 答案不够具体或过于具体
